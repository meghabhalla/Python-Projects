## Getting data from multiple web pages
import requests
import time # to have time intervals between each request to the server
import pandas as pd #importing pandas to create a dataframe
from bs4 import BeautifulSoup as bs #library used for web scraping

base_url = "http://www.pyclass.com/real-estate/rock-springs-wy/LCWYROCKSPRINGS/#t=0&s=0" #Cached page of Century21

l= []
for page in range(0,30,10):
    print(base_url+str(page))
    r = requests.get(base_url+str(page)+'.html', headers={'User-agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:61.0) Gecko/20100101 Firefox/61.0'})
    c = r.content
    soup = bs(c,"html.parser")
    #print(soup.prettify()) # prettify makes it in a readable format
    all = soup.find_all("div",{'class':'propertyRow'})
    
    for item in all:
        d = {}
        d['Price'] = item.find('h4',{'class':"propPrice"}).text.replace('\n','').replace(' ','')
        d['Address']=(item.find_all('span',{'class':"propAddressCollapse"})[0].text)
        d['Locality']=(item.find_all('span',{'class':"propAddressCollapse"})[1].text)
        try:
           # print(item.find('span',{'class':"infoBed"}).text) result will be x Beds
            d['Beds']=(item.find('span',{'class':"infoBed"}).find("b").text) # getting only the number as result
        except:
            d['Beds'] = None
        try:
            d['Full_Bathrooms'] =(item.find('span',{'class':"infoValueFullBath"}).text) # getting the number of full bathrooms
        except:
            d['Full_Bathrooms']=None
        try:
            d['Area'] =(item.find('span',{'class':"infoSqFt"}).text) 
        except:
            d['Area'] =None
        for column_group in item.find_all('div',{'class':'columnGroup'}):
            for feature_group, feature_name in zip (column_group.find_all('span',{'class':'featureGroup'}),column_group.find_all('span',{'class':'featureName'})):
                if 'Lot Size' in feature_group.text:
                    d['Lot Size'] =  (feature_name.text)
        l.append(d)
    time.sleep(3) #So that the server is not overloaded with requests
df = pd.DataFrame(l)
df.to_csv('Century21_output.csv') #To get the output in csv format
